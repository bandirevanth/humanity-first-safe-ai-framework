# Security Policy

## Supported Versions
This repository currently maintains **all active branches**.  
Security updates will be applied to the latest release (`main`) and tagged versions.  

| Version | Supported          |
| ------- | ------------------ |
| 1.0     | :white_check_mark: |
| <1.0    | :x:                |

## Reporting a Vulnerability
If you discover a security vulnerability, please follow **responsible disclosure** practices:
1. **Do not open a public GitHub issue** with sensitive details.  
2. Instead, email the maintainer directly:  
   **ðŸ“§ 5825bandirevanth@gmail.com**
3. Provide as much detail as possible, including:
   - A clear description of the vulnerability  
   - Steps to reproduce  
   - Possible impact  
   - Any suggested fixes  

The maintainer will acknowledge receipt within **48 hours** and provide a timeline for a fix.  

## Security Principles
This project follows a **human-first, safety-first approach**. All reported issues will be prioritized according to:
1. **Potential harm to humans**  
2. **Risk of AI misuse or unsafe behavior**  
3. **Compliance with government rules and regulations**  

## Scope
This repository includes:
- `RULES.json` (the AI safety ruleset)  
- All documentation (`README.md`, `NOTICE.md`, `principles.md`, etc.)  
- Example enforcement code in `/examples`  

Security vulnerabilities may involve:
- Incorrect interpretation of rules  
- Rule bypass techniques  
- Weaknesses in logging, auditing, or enforcement design  

## Out of Scope
- Issues unrelated to the ruleset (e.g., vulnerabilities in unrelated AI libraries or hosting providers).  
- Misuse by developers who intentionally ignore or remove the framework safeguards.  

## Attribution
Project created and maintained by **Bandi Revanth**.  
Â© 2025. All rights reserved. Humanity-First AI Safety Rules â€” copyright and authorship fully owned by Bandi Revanth.  
